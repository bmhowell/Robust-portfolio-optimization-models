{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1dbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty model:\n",
    "\n",
    "We assume that the returns are random, independent of the form $r_i = \\hat{r}_i + \\sigma_i u_i$, where $u \\in [-1, 1]^{n+1}$. Let $\\mathcal{P}$ be the corresponding class of distribution $\\pi$ of vector $r$. \n",
    "\n",
    "We seek to solve the problem: $$\\max_{x,t} t : \\forall \\pi \\in \\mathcal{P} : \\mathbf{Prob}_\\pi\\{r^Tx \\geq t\\} \\geq 1 - \\epsilon$$ \n",
    "\n",
    "In our experiment we assume that $n=200$ and $\\hat{r}_i = 1.05 + 0.3(200 - i)/199$, $\\sigma_i = 0.05 + 0.6(200-i)/199$, with $\\sigma_{n+1} = 0$. \n",
    "\n",
    "\n",
    "#### model: Purely robust counterpart using only support information: $u \\in [-1, 1]^{n+1}$\n",
    "\n",
    "We would like to maximize profit, therefore the optimization problem in standard form is:\n",
    "\n",
    "$$\\max_x \\quad r^Tx : 1^Tx = 1, x \\geq 0$$\n",
    "\n",
    "\n",
    "where $r$ exists in the uncertainty set:\n",
    "\n",
    "$$\\mathcal{U} = \\{r_i = \\hat{r}_i + \\sigma_i u_i : |u_i| \\leq 1\\}$$\n",
    "\n",
    "Since the extreme case for box uncertainty is always $u = 1$ or $|u_i| = |x_i|$, the worst case minimum:\n",
    "$$\\max_{r\\in \\mathcal{U}} \\quad \\hat{r}^Tx - \\sum^m_{i=1} \\sigma_i |x_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.352 1.35  1.348 1.347 1.345 1.344 1.342 1.341 1.339 1.338 1.336 1.335\n",
      " 1.333 1.332 1.33  1.329 1.327 1.326 1.324 1.323 1.321 1.32  1.318 1.317\n",
      " 1.315 1.314 1.312 1.311 1.309 1.308 1.306 1.305 1.303 1.302 1.3   1.299\n",
      " 1.297 1.296 1.294 1.293 1.291 1.29  1.288 1.287 1.285 1.284 1.282 1.281\n",
      " 1.279 1.278 1.276 1.275 1.273 1.272 1.27  1.269 1.267 1.266 1.264 1.263\n",
      " 1.261 1.26  1.258 1.257 1.255 1.254 1.252 1.251 1.249 1.247 1.246 1.244\n",
      " 1.243 1.241 1.24  1.238 1.237 1.235 1.234 1.232 1.231 1.229 1.228 1.226\n",
      " 1.225 1.223 1.222 1.22  1.219 1.217 1.216 1.214 1.213 1.211 1.21  1.208\n",
      " 1.207 1.205 1.204 1.202 1.201 1.199 1.198 1.196 1.195 1.193 1.192 1.19\n",
      " 1.189 1.187 1.186 1.184 1.183 1.181 1.18  1.178 1.177 1.175 1.174 1.172\n",
      " 1.171 1.169 1.168 1.166 1.165 1.163 1.162 1.16  1.159 1.157 1.156 1.154\n",
      " 1.153 1.151 1.149 1.148 1.146 1.145 1.143 1.142 1.14  1.139 1.137 1.136\n",
      " 1.134 1.133 1.131 1.13  1.128 1.127 1.125 1.124 1.122 1.121 1.119 1.118\n",
      " 1.116 1.115 1.113 1.112 1.11  1.109 1.107 1.106 1.104 1.103 1.101 1.1\n",
      " 1.098 1.097 1.095 1.094 1.092 1.091 1.089 1.088 1.086 1.085 1.083 1.082\n",
      " 1.08  1.079 1.077 1.076 1.074 1.073 1.071 1.07  1.068 1.067 1.065 1.064\n",
      " 1.062 1.061 1.059 1.058 1.056 1.055 1.053 1.052 1.05 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "0.9999999999569859\n"
     ]
    }
   ],
   "source": [
    "n = 201\n",
    "rhat = [1.05 + 0.3*(200 - i)/199 for i in range(n)]\n",
    "print(np.round(rhat, 3))\n",
    "sig = [0.05 + 0.6*(200 - i)/199 for i in range(n)]\n",
    "x = cp.Variable(n)\n",
    "\n",
    "obj = cp.Maximize(rhat @ x - sig@x)\n",
    "\n",
    "constraints = [x >= 0,\n",
    "              np.ones(n)@x == 1]\n",
    "\n",
    "prob = cp.Problem(obj, constraints)\n",
    "prob.solve()\n",
    "optimalX = np.round(x.value, 2)\n",
    "profit = prob.value\n",
    "print(optimalX)\n",
    "print(prob.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this first model, a purely approach leads to the very conservative investment of putting everything in the risk-free asset; the worst-case return is the risk-free return, 1.05, in the last slot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach is the chance counterpart described in page 23-24 of Module 3, with \n",
    "\n",
    "$$R = \\mathbf{diag}(\\sigma)$$\n",
    "\n",
    "With a reliability parameter $\\epsilon = 0.005$.\n",
    "\n",
    "The chance constraint:\n",
    "\n",
    "$$\\hat{r}^Tx + \\rho(\\epsilon) ||R^Tx||_2 \\leq b,$$ \n",
    "\n",
    "and the robust counterpart with the uncertainty set:\n",
    "\n",
    "$$\\mathcal{U} := \\{\\hat{r} + Ru : ||u||_2 \\leq \\rho(\\epsilon)\\}$$\n",
    "\n",
    "where $\\rho(\\epsilon):= \\sqrt{2log(1/\\epsilon)}$. \n",
    "\n",
    "Thus we can rewrite the deterministic counter part from:\n",
    "\n",
    "$$\\forall \\pi \\in \\mathcal{P} : \\mathbf{Prob}_\\pi \\{r : r^Tx \\leq t\\} 1 - \\epsilon \\Longleftrightarrow \\hat{r}^Tx - \\rho(\\epsilon) ||R^Tx||_2 \\leq t$$\n",
    "\n",
    "Thus the optimization problem becomes a SOC optimization problem:\n",
    "\n",
    "$$\\max_{x,t} t$$\n",
    "$$\\textit{s.t.} \\quad -\\hat{r}^Tx + \\rho(\\epsilon)||R^Tx||_2 \\leq -t, \\\\ x \\geq 0, \\\\ 1^Tx = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.  ]\n",
      "1.1207407663815445\n"
     ]
    }
   ],
   "source": [
    "eps = 0.005\n",
    "R = sig * np.eye(n)\n",
    "rho = np.sqrt(2*np.log(1/eps))\n",
    "\n",
    "x = cp.Variable(n)\n",
    "t = cp.Variable()\n",
    "obj2 = cp.Maximize(t)\n",
    "constraints2 = [x >= 0, \n",
    "               np.ones(n)@x == 1, \n",
    "               cp.SOC(-t + rhat@x, -rho* R.T @ x)]\n",
    "prob = cp.Problem(obj2, constraints2)\n",
    "prob.solve()\n",
    "optimalX = np.round(x.value, 2)\n",
    "profit = prob.value\n",
    "print(optimalX)\n",
    "print(prob.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model gives a worst-case return of 1.12% with a 0.5% chance of not getting this return. \n",
    "\n",
    "Thus we observe that the chance constrains allow to make the robustness condition much less conservative, at the expense of a very slight increase in risk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
